%!TEX root = htm.tex
\section{Introduction}
\label{sec:intro}
%
%
The \emph{Transactional Memory (TM)} abstraction is a synchronization mechanism 
that allows the programmer to \emph{optimistically} execute sequences of shared-memory
operations as \emph{atomic transactions}.
Several software TM designs~\cite{norec, ST95,HLM+03, astm, fraser} have been introduced subsequent to the original TM proposal based in
hardware~\cite{HM93}. 
The original dynamic STM implementation DSTM~\cite{HLM+03} ensures that a transaction aborts only if there is a read-write \emph{data conflict} with a concurrent
transaction (\`a la \emph{progressiveness}~\cite{tm-book}). However, read operations in DSTM must \emph{incrementally} validate
the responses of all previous read operations to avoid inconsistent executions. 
This results in quadratic  (in the size of the transaction's read
set) step-complexity for transactions. Subsequent STM 
implementations like NOrec~\cite{norec} and TL2~\cite{DSS06}
minimize the impact on performance due to incremental validation.
NOrec uses a global sequence lock that is read at the start of a transaction and performs \emph{value-based}
validation during read operations only if the value of the global lock has changed (by an updating transaction) 
since reading it.
TL2, on the other hand, eliminates incremental validation completely.
Like NOrec, it uses a global sequence lock, but each data item also 
has an associated sequence lock value that is updated alongside the data item.
When a data item is read, if its associated sequence lock value is different 
from the value that was read from the sequence lock at the start of the transaction, then the transaction aborts.

In fact, STMs like TL2 and NOrec ensure progress in the absence of data conflicts with 
O(1) step complexity read operations and \emph{invisible reads} (read operations 
do not modify shared memory) 
Nonetheless, TM designs that are implemented entirely in software still incur significant performance overhead.
Thus, current CPUs have included instructions to mark a block of memory accesses as transactional~\cite{Rei12, asf, bluegene}, allowing them to be executed \emph{atomically} in hardware.
Hardware transactions promise better performance than STMs, but they offer no progress guarantees 
since they may experience \emph{spurious} aborts. This motivates the need for
\emph{hybrid} TMs in which the \emph{fast} hardware transactions are 
complemented with \emph{slower} software transactions that do not have spurious aborts.

To allow hardware transactions in a HyTM to detect conflicts with software transactions, they must be \emph{instrumented} to perform additional metadata accesses, which introduces overhead.
Hardware transactions typically provide automatic conflict detection at cacheline granularity,
thus ensuring that the transaction itself would be aborted if it experiences memory contention on the cacheline.
This is at least the case with Intel's Transactional Synchronization Extensions~\cite{haswell}.
The IBM Power8 ISA additionally allows hardware transactions to access metadata \emph{non-speculatively}, 
thus bypassing automatic conflict detection. While this has the advantage of potentially reducing contention aborts
in hardware, this makes the design of HyTM implementations potentially harder to prove correct.

In \cite{htmdisc15}, it was shown that hardware transactions in progressive HyTMs must perform
at least one metadata access per transactional read and write.
In this paper, we show that in progressive HyTMs with invisible reads, 
software transactions \textit{cannot} avoid incremental validation.
Specifically, we prove that \textit{each read operation} of a software transaction in a progressive HyTM
must necessarily incur a validation cost that is \emph{linear} 
in the size of the transaction's read set. 
This is in contrast to TL2 which is progressive and has constant complexity read operations.
Thus, in addition to the linear instrumentation cost in hardware transactions, there is a quadratic step complexity cost in software transactions.

We then present \emph{opaque} HyTM algorithms providing \emph{progressiveness for a subset of transactions} that are  %both hardware and software transactions \trevor{maybe just ``transactions''?}
optimal in terms of hardware instrumentation.
Algorithm~1 is progressive for all transactions, but it incurs high instrumentation overhead in practice.
Algorithm~2 avoids all instrumentation in fast-path read operations, but is progressive only for slow-path reading transactions.
We also sketch how \emph{some} hardware instrumentation can be performed \textit{non-speculatively} without violating opacity.

We performed experiments comparing our HyTM algorithms to TL2, Transactional Lock Elision (TLE) and Hybrid NOrec~\cite{hynorecriegel} 
using a binary search tree microbenchmark.
In these experiments, we studied two types of workloads: workloads in which essentially all transactions commit on the fast-path, 
and workloads in which some thread periodically performs transactions on the slow-path.
These experiments demonstrate that hardware instrumentation is a dominating factor in the performance of HyTMs, 
and that simplistic algorithms like TLE perform very well unless transactions periodically run on the slow-path.

Our experiments with Intel and IBM Power8 HTMs   
seem to suggest that (i) the \emph{cost of concurrency} also exists in practice, (ii) it is important to build HyTMs that provide progressiveness for a maximal set of transactions with minimal fast-path instrumentation
without using global contending bottlenecks and (iii) there is no easy to way to derive more efficient HyTMs by taking advantage of non-speculative accesses within the fast-path.

%We explore the concurrency vs. hardware instrumentation vs. software validation tradeoffs for these algorithms.
%Preliminary experiments on Intel Haswell (resp. IBM Power 8) not supporting (resp. supporting) non-speculative accesses inside hardware,
%seem to suggest that the inherent \emph{cost to concurrency} in HyTMs also exists in practice and discuss algorithmic techniques to overcome them.

\vspace{1mm}\noindent\textbf{Roadmap.}
\cref{sec:hytm} presents details of the HyTM model that extends the model introduced in \cite{htmdisc15} 
to access memory locations non-speculatively.
\cref{sec:lb} presents our main lower bound result on the step-complexity of progressive HyTMs
while \cref{sec:hytmalgos} presents several opaque HyTM algorithms.
\cref{sec:eval} summarizes resuls from our experiments on Intel Haswell and IBM Power 8 architectures.
\cref{sec:rel} presents the related work along with concluding remarks.
%